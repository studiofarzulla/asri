% ============================================================================
% Supplementary Materials
% ASRI: An Aggregated Systemic Risk Index for Cryptocurrency Markets
% ============================================================================
% Authors: Murad Farzulla, Andrew Maksakov
% ============================================================================

\documentclass[11pt]{article}

% ============================================================================
% PACKAGE IMPORTS
% ============================================================================

% Page geometry and layout
\usepackage[a4paper, margin=1in]{geometry}
\usepackage{setspace}

% Fonts and typography
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% Graphics and figures
\usepackage{graphicx}
\usepackage{float}
\graphicspath{{figures/}}

% Tables
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{threeparttable}

% Math packages
\usepackage{amsmath}
\usepackage{amssymb}

% Lists with custom labels
\usepackage{enumitem}

% Colored boxes
\usepackage{tcolorbox}

% Verbatim
\usepackage{verbatim}

% Bibliography
\usepackage[round,authoryear]{natbib}
\bibliographystyle{plainnat}

% Hyperlinks and PDF metadata
\usepackage[colorlinks=true,
            linkcolor=blue,
            citecolor=blue,
            urlcolor=blue,
            breaklinks=true,
            pdftitle={Supplementary Materials: ASRI},
            pdfauthor={Murad Farzulla, Andrew Maksakov}]{hyperref}

% ============================================================================
% DOCUMENT
% ============================================================================

\begin{document}

\title{Supplementary Materials: ASRI: An Aggregated Systemic Risk Index for Cryptocurrency Markets}
\author{Murad Farzulla \and Andrew Maksakov}
\date{}
\maketitle

\appendix

% ============================================================================
% APPENDIX A: DETAILED COMPONENT SPECIFICATIONS
% ============================================================================

\section{Detailed Component Specifications}\label{app:components}

This appendix provides exact formulas for all ASRI sub-components as implemented in the reference codebase. Where practical data constraints necessitate proxy measures, we document both the theoretical specification and the implemented approximation, with justification for why the proxy preserves the intended risk signal.

\subsection{Stablecoin Concentration Risk (SCR)}
\textbf{Weight:} 30\%

The Stablecoin Concentration Risk sub-index captures vulnerabilities arising from reserve composition, peg stability, and issuer concentration.

\subsubsection{TVL Ratio ($\text{TVL}_t$)}
\textbf{Data Source:} DeFi Llama API (\texttt{api.llama.fi/v2/historicalChainTvl}), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{TVL}_{\text{raw}} = \frac{\text{Current Stablecoin TVL}_t}{\max_{\tau \leq t}(\text{Stablecoin TVL}_\tau)}
\end{equation}

The raw ratio is inverted and normalized to produce a risk score:
\begin{equation}
\text{TVL}_t = \text{normalize}(1 - \text{TVL}_{\text{raw}}, 0, 0.5) \times 100
\end{equation}

\textbf{Interpretation:} At maximum historical TVL, the component equals 0 (low risk). At 50\% of historical maximum, the component approaches 100 (high risk). This captures the intuition that significant TVL drawdowns indicate stress or capital flight.

\textbf{Normalization:} Clipped to $[0, 100]$ via min-max scaling with theoretical bounds.

\subsubsection{Treasury Stress ($\text{Treasury}_t$)}
\textbf{Data Source:} FRED API (\texttt{DGS10} series), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Treasury}_t = \frac{r_{10Y,t} - r_{\min}}{r_{\max} - r_{\min}} \times 100
\end{equation}

where $r_{10Y,t}$ is the 10-Year Treasury Constant Maturity Rate, $r_{\min} = 2.0\%$, and $r_{\max} = 6.0\%$.

\textbf{Interpretation:} Higher Treasury yields increase stress on stablecoin reserves (which typically hold short-term Treasuries) through mark-to-market losses and opportunity cost dynamics. The 2--6\% bounds reflect the observed range during the sample period.

\textbf{Implementation Note:} The paper's theoretical specification describes $\text{Treasury}_t$ as the ratio of T-Bill reserves to total reserves. The implementation uses Treasury yield levels as a proxy because reserve composition data is available only through monthly attestation reports with significant reporting lags. Treasury yields provide a higher-frequency signal of the same underlying risk: reserve stress from interest rate movements.

\subsubsection{Concentration HHI ($\text{HHI}_t$)}
\textbf{Data Source:} DeFi Llama Stablecoins API (\texttt{stablecoins.llama.fi/stablecoins}), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{HHI}_{\text{raw}} = \sum_{i=1}^{n} \left(\frac{S_i}{\sum_{j=1}^{n} S_j}\right)^2 \times 10000
\end{equation}

where $S_i$ is the circulating supply of stablecoin $i$.

The raw HHI is converted to a risk score using a piecewise mapping:
\begin{equation}
\text{HHI}_t = \begin{cases}
\frac{\text{HHI}_{\text{raw}}}{1500} \times 30 & \text{if HHI} < 1500 \\[0.5em]
30 + \frac{\text{HHI}_{\text{raw}} - 1500}{1000} \times 30 & \text{if } 1500 \leq \text{HHI} < 2500 \\[0.5em]
60 + \frac{\text{HHI}_{\text{raw}} - 2500}{2500} \times 30 & \text{if } 2500 \leq \text{HHI} < 5000 \\[0.5em]
90 + \frac{\text{HHI}_{\text{raw}} - 5000}{5000} \times 10 & \text{if HHI} \geq 5000
\end{cases}
\end{equation}

\textbf{Interpretation:} The thresholds follow standard antitrust guidelines: HHI $<$ 1500 indicates a competitive market; 1500--2500 indicates moderate concentration; $>$ 2500 indicates high concentration. The piecewise function maps these to risk scores of 0--30, 30--60, and 60--100 respectively.

\subsubsection{Peg Volatility ($\text{Vol}_t$)}
\textbf{Data Source:} DeFi Llama Stablecoins API (price field), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Vol}_t = \frac{\sum_{i=1}^{n} |p_i - 1| \cdot S_i}{\sum_{j=1}^{n} S_j} \times 20
\end{equation}

where $p_i$ is the current price of stablecoin $i$ and $S_i$ is its circulating supply.

\textbf{Normalization:} 0\% weighted deviation maps to 0 risk; 5\% weighted deviation maps to 100 risk.

\textbf{Missing Data:} If no price data is available, the component defaults to 50.0 (neutral).

\subsubsection{SCR Aggregation}
\begin{equation}
\text{SCR}_t = 0.4 \cdot \text{TVL}_t + 0.3 \cdot \text{Treasury}_t + 0.2 \cdot \text{HHI}_t + 0.1 \cdot \text{Vol}_t
\end{equation}

\subsubsection{Algorithmic Stablecoin Risk Extension (v2.1)}\label{subsubsec:algo_stable}

The baseline SCR formula treats all stablecoins identically via peg volatility ($\text{Vol}_t$). However, the Terra/Luna collapse (May 2022) revealed that peg volatility is a \textit{lagging} indicator for algorithmic stablecoins: UST maintained its peg until the death spiral commenced, and Luna's price appreciation masked underlying fragility. This extension addresses the detection gap by incorporating risk factors specific to algorithmic and crypto-backed stablecoins.

\paragraph{Motivation.}
Fiat-collateralized stablecoins (USDT, USDC) are backed by liquid reserves redeemable at par. Algorithmic stablecoins maintain peg through arbitrage mechanisms between the stablecoin and a backing token---creating reflexive dynamics where redemption pressure inflates backing token supply, diluting its value, which further increases redemption pressure. This death spiral mechanism is distinct from the reserve-based risks captured by baseline SCR components.

\paragraph{Algorithmic Stablecoin Risk Formula.}
For stablecoins classified as algorithmic or crypto-backed, we compute:
\begin{equation}
\text{AlgoRisk}_t = 0.35 \cdot \text{BackingRatio}_t + 0.30 \cdot \text{CollateralVol}_t + 0.20 \cdot \text{Dilution}_t + 0.15 \cdot \text{AlgoConc}_t
\end{equation}

\textbf{Component definitions:}
\begin{itemize}
    \item \textbf{BackingRatio$_t$}: Risk from undercollateralization. Backing ratio $\geq 1.5$ maps to low risk (0--20); ratio $< 0.8$ maps to critical risk (80--100). For stablecoins without explicit backing disclosure, defaults to moderate risk (50).
    \item \textbf{CollateralVol$_t$}: Annualized 30-day volatility of backing token. ETH volatility ($\sim$60--80\%) maps to moderate risk; Luna-type volatility ($>$100\%) maps to elevated/critical risk.
    \item \textbf{Dilution$_t$}: 30-day supply growth rate of backing token. Monthly growth $>50\%$ signals crisis-level dilution (Luna supply grew $\sim$50,000\% during collapse).
    \item \textbf{AlgoConc$_t$}: Share of total stablecoin supply in algorithmic/crypto-backed stablecoins. At peak, UST represented $\sim$10\% of total stablecoin supply.
\end{itemize}

\paragraph{Integration with SCR.}
Let $\alpha_t$ denote the market share of algorithmic stablecoins in total stablecoin supply. The adjusted SCR blends baseline and algorithmic risk:
\begin{equation}
\text{SCR}_t^{\text{adj}} = (1 - \alpha_t) \cdot \text{SCR}_t^{\text{base}} + \alpha_t \cdot \left[0.6 \cdot \text{SCR}_t^{\text{base}} + 0.4 \cdot \text{AlgoRisk}_t\right]
\end{equation}

When $\alpha_t < 1\%$, the adjustment is negligible. When $\alpha_t = 10\%$ (approximate UST peak share), algorithmic-specific risk contributes 4\% to SCR weighting.

\paragraph{Data Requirements.}
Full implementation requires:
\begin{enumerate}
    \item \textbf{Stablecoin classification}: DeFi Llama \texttt{pegType}/\texttt{pegMechanism} fields or manual classification (provided in codebase).
    \item \textbf{Backing token identification}: Mapping from stablecoin to backing token (e.g., UST $\to$ LUNA).
    \item \textbf{Backing token metrics}: Price volatility and supply data from CoinGecko or on-chain indexers.
\end{enumerate}

\paragraph{Backtest Limitation.}
Historical reconstruction of AlgoRisk$_t$ for pre-collapse Terra/Luna requires archived Luna price and supply data. While DeFi Llama and CoinGecko retain historical snapshots, consistent backing ratio data for UST is not systematically available. The specification documents the \textit{framework} for future algorithmic stablecoin risk monitoring; full historical backtest validation awaits improved data infrastructure. Sensitivity analysis suggests that with accurate Luna volatility data (annualized vol $>$120\% in April 2022), the extension would have elevated SCR by approximately 8--12 points prior to UST's depeg---potentially bringing ASRI above the detection threshold.

\subsection{DeFi Liquidity Risk (DLR)}
\textbf{Weight:} 25\%

The DeFi Liquidity Risk sub-index captures protocol concentration, volatility dynamics, and smart contract vulnerability.

\subsubsection{Protocol Concentration ($\text{Conc}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{api.llama.fi/protocols}), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Conc}_t = f_{\text{HHI}}\left(\sum_{i=1}^{10} \left(\frac{\text{TVL}_i}{\sum_{j=1}^{10} \text{TVL}_j}\right)^2 \times 10000\right)
\end{equation}

where $f_{\text{HHI}}$ is the piecewise HHI-to-risk mapping defined above, and the summation is over the top 10 protocols by TVL.

\textbf{Interpretation:} Concentration among the largest protocols indicates ecosystem fragility---failure of a dominant protocol would have outsized systemic effects.

\subsubsection{TVL Volatility ($\text{TVLVol}_t$)}
\textbf{Data Source:} DeFi Llama TVL history, 30-day rolling window.

\textbf{Formula:}
\begin{equation}
\text{TVLVol}_t = \text{normalize}\left(\frac{\sigma_{30}(\text{TVL})}{\mu_{30}(\text{TVL})}, 0, 0.20\right) \times 100
\end{equation}

where $\sigma_{30}$ and $\mu_{30}$ denote the 30-day rolling standard deviation and mean.

\textbf{Normalization:} 0\% coefficient of variation maps to 0 risk; 20\% maps to 100 risk.

\textbf{Missing Data:} If historical TVL data is unavailable (fewer than 2 observations), the component defaults to 30.0 (moderate).

\subsubsection{Smart Contract Risk ($\text{SC}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{audits} field), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{SC}_t = \left(1 - \frac{|\{p : \text{audits}(p) > 0\}|}{|\{p : \text{TVL}(p) > 0\}|}\right) \times 100
\end{equation}

\textbf{Interpretation:} The component measures the inverse of audit coverage across protocols with non-zero TVL. Protocols lacking audits receive the full risk weight.

\textbf{Theoretical vs. Implemented Specification:} The paper describes a 3-factor composite incorporating audit status, deployment age, and exploit history. The current implementation uses audit coverage only. Deployment age and exploit history integration are deferred to future versions pending reliable, systematized data feeds. The DeFi Llama API provides audit counts but not deployment timestamps or comprehensive exploit databases.

\textbf{Justification:} Audit coverage remains the most reliable and consistently available indicator of smart contract risk. Empirical research demonstrates strong correlation between unaudited protocols and exploit frequency, supporting the proxy's validity.

\subsubsection{Flash Loan Proxy ($\text{Flash}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{change\_1d} field), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Flash}_t = \text{normalize}\left(\frac{1}{n}\sum_{i=1}^{n} |\Delta_{\text{1d},i}|, 0, 20\right) \times 100
\end{equation}

where $\Delta_{\text{1d},i}$ is the 1-day TVL change percentage for protocol $i$.

\textbf{Theoretical vs. Implemented Specification:} The paper describes flash loan volume spikes relative to a 90-day average. Direct flash loan volume data requires protocol-specific analytics (e.g., Aave, dYdX subgraphs) with heterogeneous reporting standards. The implementation uses aggregate TVL volatility as a proxy, on the reasoning that flash loan activity manifests as rapid TVL movements during MEV extraction and liquidation cascades.

\textbf{Normalization:} 0\% average daily change maps to 0 risk; 20\% maps to 100 risk.

\subsubsection{Leverage Change ($\text{Lev}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{category} field), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Lev}_t = \text{normalize}\left(\frac{\sum_{p \in \text{Lending}} \text{TVL}_p}{\sum_{p} \text{TVL}_p} \times 100, 0, 30\right) \times 100
\end{equation}

\textbf{Interpretation:} A higher share of TVL in lending protocols indicates greater system-wide leverage. The 30\% threshold reflects the upper bound of lending protocol dominance observed during market stress.

\textbf{Theoretical vs. Implemented Specification:} The paper describes 30-day change in aggregate leverage ratios. The implementation uses the current lending TVL share as a level indicator rather than a change measure, because reliable historical leverage data across protocols is not consistently available.

\subsubsection{DLR Aggregation}
\begin{equation}
\text{DLR}_t = 0.35 \cdot \text{Conc}_t + 0.25 \cdot \text{TVLVol}_t + 0.20 \cdot \text{SC}_t + 0.10 \cdot \text{Flash}_t + 0.10 \cdot \text{Lev}_t
\end{equation}

\subsection{Contagion Risk (CR)}
\textbf{Weight:} 25\%

The Contagion Risk sub-index quantifies DeFi-TradFi interconnection and cross-market transmission channels.

\subsubsection{RWA Growth ($\text{RWA}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{category = 'RWA'}), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{RWA}_t = \text{normalize}\left(\frac{\sum_{p \in \text{RWA}} \text{TVL}_p}{\sum_{p} \text{TVL}_p} \times 100, 0, 10\right) \times 100
\end{equation}

\textbf{Interpretation:} Higher RWA share indicates greater integration between DeFi and traditional finance through tokenized real-world assets. The 10\% threshold reflects the upper bound of RWA penetration observed during the sample period.

\textbf{Theoretical vs. Implemented Specification:} The paper describes 30-day RWA TVL growth rate. The implementation uses the current RWA share as a level indicator, because RWA protocols have short histories making growth rate calculations unreliable for early-period observations.

\subsubsection{Bank Exposure ($\text{Bank}_t$)}
\textbf{Data Sources:} FRED API (\texttt{DGS10} for Treasury rates, \texttt{VIXCLS} for VIX), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Bank}_t = 0.6 \cdot \text{normalize}(r_{10Y,t}, 2, 6) + 0.4 \cdot \text{normalize}(\text{VIX}_t, 12, 40)
\end{equation}

\textbf{Interpretation:} The composite captures TradFi stress through two channels: Treasury rate levels (affecting stablecoin reserves and bank balance sheets) and equity market volatility (signaling broader risk-off sentiment).

\textbf{Weight and Range Justification:} The 60/40 weighting reflects Treasury yields' direct balance-sheet impact on bank capital ratios versus VIX's indirect sentiment signal. Banks holding Treasury securities face mark-to-market losses when yields rise (the primary channel), while VIX captures risk-off dynamics that tighten credit conditions (secondary channel). The normalization ranges (2--6\% for 10Y Treasury, 12--40 for VIX) span the 5th--95th percentiles of 2015--2024 sample data, ensuring meaningful variation without clipping at extremes.

\textbf{Theoretical vs. Implemented Specification:} The paper describes a normalized score from OCC/ECB regulatory filings on bank crypto exposure. Regulatory filings are quarterly with 45--90 day publication lags, making them unsuitable for daily risk monitoring. The Treasury-VIX composite provides a higher-frequency proxy: banks with crypto exposure face stress when Treasury yields rise (mark-to-market losses) and when VIX spikes (risk management constraints).

\subsubsection{TradFi Linkage ($\text{Link}_t$)}
\textbf{Data Source:} FRED API (\texttt{T10Y2Y} series), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Link}_t = \begin{cases}
\text{normalize}(|s_t|, 0, 2) \times 100 + 50 & \text{if } s_t < 0 \\[0.5em]
\max(0, 50 - \text{normalize}(s_t, 0, 2) \times 50) & \text{if } s_t \geq 0
\end{cases}
\end{equation}

where $s_t = r_{10Y,t} - r_{2Y,t}$ is the 10-Year minus 2-Year Treasury spread.

\textbf{Interpretation:} Yield curve inversion (negative spread) indicates banking sector stress and recession expectations, which propagate to crypto through reduced institutional risk appetite and potential bank failures affecting crypto-exposed entities.

\textbf{Theoretical vs. Implemented Specification:} The paper describes ``stablecoin flows to TradFi-connected entities.'' Such flow data requires enterprise-grade on-chain analytics (Chainalysis, TRM Labs) at prohibitive cost for academic research. Yield curve dynamics provide a validated proxy: the March 2023 SVB crisis demonstrated that yield curve inversion directly precedes banking stress events that propagate to crypto markets through stablecoin reserve exposure.

\textbf{Justification:} The yield curve spread has predicted every U.S. recession since 1970 with a median lead time of 12 months. Banking crises correlated with yield curve inversion directly affect crypto-TradFi linkages through stablecoin reserve exposure (as demonstrated by the USDC depeg during SVB's collapse). \citet{aufiero2025balance} quantify institutional balance sheet exposure to cryptocurrency, documenting significant BTC beta among publicly-traded firms and validating the empirical relevance of yield-curve-based proxies for institutional crypto stress.

\subsubsection{Correlation ($\text{Corr}_t$)}
\textbf{Data Source:} External calculation (BTC-SPY 30-day rolling correlation).

\textbf{Formula:}
\begin{equation}
\text{Corr}_t = |r_{\text{BTC-SPY}, 30d}| \times 100
\end{equation}

\textbf{Interpretation:} Higher absolute correlation indicates greater co-movement between crypto and equities, implying tighter contagion channels.

\textbf{Implementation Note:} The current implementation accepts correlation as an external input with a default of 0.5 (moderate). Real-time calculation requires equity price feeds (Yahoo Finance, Bloomberg) not included in the core data pipeline.

\subsubsection{Bridge Risk ($\text{Bridge}_t$)}
\textbf{Data Source:} DeFi Llama Bridges API (\texttt{bridges.llama.fi/bridges}), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Bridge}_t = \text{normalize}(n_{\text{bridges}}, 0, 150) \times 100
\end{equation}

where $n_{\text{bridges}}$ is the count of active cross-chain bridges.

\textbf{Interpretation:} More bridges indicate larger attack surface and greater cross-chain contagion potential.

\textbf{Theoretical vs. Implemented Specification:} The paper describes a composite of bridge volume and exploit frequency. Exploit frequency data requires manual tracking (DeFi Rekt database) with inconsistent categorization. Bridge count provides a structural proxy: empirical research finds exploit frequency scales with the number of bridge implementations due to varying security standards and code quality.

\subsubsection{CR Aggregation}
\begin{equation}
\text{CR}_t = 0.30 \cdot \text{RWA}_t + 0.25 \cdot \text{Bank}_t + 0.20 \cdot \text{Link}_t + 0.15 \cdot \text{Corr}_t + 0.10 \cdot \text{Bridge}_t
\end{equation}

\subsection{Regulatory Opacity Risk (OR)}
\textbf{Weight:} 20\%

The Regulatory Opacity Risk sub-index assesses transparency deficits and regulatory arbitrage exposure.

\subsubsection{Unregulated Exposure ($\text{Unreg}_t$)}
\textbf{Data Source:} Placeholder component (see Table~\ref{tab:proxies} for implementation status).

\textbf{Implementation:} Fixed at 35.0 (moderate risk), corresponding to estimated market share of volume on platforms without clear regulatory oversight.

\textbf{Theoretical Specification:} Ratio of volume on unregulated platforms to regulated platforms. Full implementation requires mapping protocols to jurisdictional regulatory status, which involves manual classification and ongoing tracking of regulatory developments across 50+ jurisdictions.

\textbf{Future Enhancement:} Chain-level classification (e.g., Ethereum as ``regulated-adjacent'' due to U.S. regulatory engagement vs. privacy chains) would enable dynamic calculation.

\subsubsection{Multi-Issuer Risk ($\text{Multi}_t$)}
\textbf{Data Source:} DeFi Llama Stablecoins API, daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Multi}_t = \begin{cases}
70 & \text{if } n_{\text{sig}} < 3 \\[0.5em]
30 & \text{if } 3 \leq n_{\text{sig}} < 10 \\[0.5em]
50 + 2(n_{\text{sig}} - 10) & \text{if } n_{\text{sig}} \geq 10
\end{cases}
\end{equation}

where $n_{\text{sig}} = |\{s : \text{circulating}(s) > \$1\text{B}\}|$ is the count of stablecoins with circulating supply exceeding \$1 billion.

\textbf{Interpretation:} The ``sweet spot'' is 3--5 significant issuers providing diversification without fragmentation. Fewer than 3 indicates dangerous concentration; more than 10 indicates coordination challenges and potential regulatory complexity.

\subsubsection{Custody Concentration ($\text{Cust}_t$)}
\textbf{Data Source:} DeFi Llama Stablecoins API, daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Cust}_t = \text{normalize}\left(\frac{\sum_{i=1}^{2} S_i}{\sum_{j} S_j} \times 100, 50, 100\right) \times 100
\end{equation}

where $S_i$ is the circulating supply of the $i$-th largest stablecoin.

\textbf{Interpretation:} Top-2 stablecoin market share as a proxy for custody concentration. Higher concentration implies greater single-point-of-failure risk regardless of custody jurisdiction.

\textbf{Theoretical vs. Implemented Specification:} The paper describes ``custody concentration in non-audited jurisdictions.'' Jurisdiction-level custody data is not systematically available; stablecoins do not consistently disclose custodian locations or regulatory status. Market concentration serves as a conservative proxy: high concentration implies custody risk regardless of location, as a single custodian failure would have systemic effects.

\subsubsection{Regulatory Sentiment ($\text{Sent}_t$)}
\textbf{Data Source:} Manual input parameter.

\textbf{Implementation:} Accepts external input with default of 50.0 (neutral). This component contributes only 15\% of the Opacity sub-index weight (3\% of total ASRI), limiting its impact on overall index behavior.

\textbf{Theoretical Specification:} NLP-derived sentiment score from SEC, ESRB, and FSB announcements. Full implementation would require:
\begin{itemize}
    \item \textbf{Sources}: GDELT Global Knowledge Graph filtered for regulatory entities (SEC, CFTC, ESRB, FSB, BIS), SEC EDGAR filings, Federal Register cryptocurrency mentions
    \item \textbf{Model}: FinBERT or domain-adapted transformer for financial regulatory text classification
    \item \textbf{Lexicon}: Crypto-specific regulatory vocabulary (``enforcement action,'' ``no-action letter,'' ``framework,'' ``guidance'') with sentiment polarity labels
    \item \textbf{De-duplication}: Entity resolution across news sources to avoid double-counting of same regulatory announcement
    \item \textbf{Jurisdictional weighting}: US (40\%), EU (30\%), UK (15\%), Other (15\%) reflecting market share
\end{itemize}

This infrastructure is deferred to future versions; current results are robust to Sent$_t$ variation due to its low aggregate weight.

\textbf{Sensitivity Analysis:} Varying Sent$_t$ from 0 (maximally positive regulatory environment) to 100 (maximally negative) while holding all other components constant produces the following ASRI impact:
\begin{equation}
\Delta\text{ASRI} = 0.20 \times 0.15 \times \Delta\text{Sent}_t = 0.03 \times \Delta\text{Sent}_t
\end{equation}

A full-range swing (Sent$_t$: 0 $\to$ 100) changes aggregate ASRI by $\pm$1.5 points. For typical variation ($\pm$25 points around neutral), ASRI changes by $\pm$0.75 points---well within the noise band of other component fluctuations.

\textbf{Detection Impact:} All four crisis events would still be detected under any Sent$_t$ value in $[0, 100]$, as the shifted thresholds remain within the detection window. The Terra/Luna event (peak 48.7 at baseline) would require Sent$_t > 93$ to breach the 50 threshold---an implausibly extreme regulatory stance.

\textbf{Future Implementation Roadmap:}
\begin{enumerate}
    \item \textbf{Phase 1}: GDELT integration with keyword filters (``SEC,'' ``CFTC,'' ``cryptocurrency,'' ``enforcement'')
    \item \textbf{Phase 2}: FinBERT deployment on SEC EDGAR cryptocurrency-related filings
    \item \textbf{Phase 3}: Multi-jurisdictional aggregation with decay weighting for announcement recency
\end{enumerate}

\subsubsection{Transparency Score ($\text{Trans}_t$)}
\textbf{Data Source:} DeFi Llama Protocols API (\texttt{audits} field), daily frequency.

\textbf{Formula:}
\begin{equation}
\text{Trans}_t = \frac{|\{p : \text{audits}(p) > 0\}|}{|\{p : \text{TVL}(p) > 0\}|} \times 100
\end{equation}

\textbf{Interpretation:} Audit coverage as a proxy for protocol transparency. The component is \textit{not} inverted at the component level; inversion occurs in the aggregation formula.

\subsubsection{OR Aggregation}
\begin{equation}
\text{OR}_t = 0.25 \cdot \text{Unreg}_t + 0.25 \cdot \text{Multi}_t + 0.20 \cdot \text{Cust}_t + 0.15 \cdot \text{Sent}_t + 0.15 \cdot (100 - \text{Trans}_t)
\end{equation}

Note the inversion of $\text{Trans}_t$: low transparency implies high opacity risk.

\subsection{Aggregate ASRI Calculation}

\begin{equation}
\text{ASRI}_t = 0.30 \cdot \text{SCR}_t + 0.25 \cdot \text{DLR}_t + 0.25 \cdot \text{CR}_t + 0.20 \cdot \text{OR}_t
\end{equation}

All sub-indices are bounded to $[0, 100]$ by construction, ensuring $\text{ASRI}_t \in [0, 100]$ without post-hoc normalization.

\subsection{Data Quality and Limitations}

\subsubsection{Data Availability Tiers}

\begin{itemize}
    \item \textbf{Tier 1 (Daily, Automated):} DeFi Llama TVL, stablecoins, protocols, bridges; FRED Treasury rates and VIX.
    \item \textbf{Tier 2 (Limited/Manual):} Regulatory sentiment, unregulated exposure classification, exploit frequency tracking.
\end{itemize}

\subsubsection{Missing Data Protocol}

\begin{itemize}
    \item Gaps $<$ 3 days: Linear interpolation.
    \item Gaps 3--7 days: Forward-fill with reduced confidence.
    \item Gaps $>$ 7 days: Exclude from calculation; flag as unreliable.
\end{itemize}

\subsubsection{Proxy Acknowledgments}

Table~\ref{tab:proxies} summarizes components where implementation deviates from theoretical specification.

\begin{table*}[h]
\begin{threeparttable}
\centering
\caption{Proxy Implementations: Theoretical vs. Actual}
\label{tab:proxies}
\small
\begin{tabularx}{\textwidth}{lXXl}
\toprule
\textbf{Component} & \textbf{Theoretical Specification} & \textbf{Implementation} & \textbf{Validity} \\
\midrule
$\text{Treasury}_t$ & T-Bill reserves / total reserves & 10Y Treasury yield level & High \\
$\text{SC}_t$ & Audit + age + exploits composite & Audit coverage only & Medium \\
$\text{Flash}_t$ & Flash loan volume spikes & TVL daily change volatility & Medium \\
$\text{Lev}_t$ & 30-day leverage ratio change & Lending TVL share (level) & Medium \\
$\text{RWA}_t$ & 30-day RWA growth rate & RWA TVL share (level) & High \\
$\text{Bank}_t$ & OCC/ECB bank exposure filings & Treasury + VIX composite & High \\
$\text{Link}_t$ & Stablecoin flows to TradFi & Yield curve spread & High \\
$\text{Bridge}_t$ & Volume + exploit frequency & Bridge count & Medium \\
$\text{Cust}_t$ & Non-audited jurisdiction custody & Top-2 stablecoin concentration & Medium \\
$\text{Unreg}_t$ & Unregulated platform ratio & Fixed (35.0)\tnote{$\dagger$} & Low \\
$\text{Sent}_t$ & NLP regulatory sentiment & Manual input (50.0)\tnote{$\dagger$} & Low \\
\bottomrule
\end{tabularx}
\begin{tablenotes}
\small
\item[$\dagger$] Placeholder components awaiting enterprise data infrastructure. Sensitivity analysis confirms all four crisis detections remain robust under full-range variation of these parameters.
\end{tablenotes}
\end{threeparttable}
\end{table*}

\textbf{Validity Legend:}
\begin{itemize}
    \item \textbf{High}: Proxy captures same underlying risk channel with strong theoretical justification and empirical support.
    \item \textbf{Medium}: Proxy captures related risk dynamics but with potential measurement error; interpretation requires caution.
    \item \textbf{Low}: Placeholder awaiting data infrastructure development; current values are informative but not definitive.
\end{itemize}

\subsubsection{Future Data Integration}

Version 3.0 development priorities include:
\begin{enumerate}
    \item Integration of exploit database (DeFi Rekt, Immunefi) for dynamic $\text{SC}_t$ and $\text{Bridge}_t$ components.
    \item Protocol deployment timestamp extraction from blockchain explorers for age-based risk weighting.
    \item GDELT/SEC filing NLP pipeline for automated regulatory sentiment scoring.
    \item Chain-level regulatory classification for dynamic $\text{Unreg}_t$ calculation.
    \item Enterprise analytics partnership (Chainalysis/TRM) for stablecoin flow analysis.
\end{enumerate}

% ============================================================================
% APPENDIX B: API DOCUMENTATION SUMMARY
% ============================================================================

\section{API Documentation Summary}

Table~\ref{tab:apis} provides endpoint documentation for primary data sources.

\begin{table*}[h]
\centering
\caption{Primary API Endpoints}
\label{tab:apis}
\small
\begin{tabularx}{\textwidth}{lXll}
\toprule
\textbf{Source} & \textbf{Endpoint} & \textbf{Rate Limit} & \textbf{Authentication} \\
\midrule
DeFi Llama & \texttt{api.llama.fi/v2/tvl} & 300/5min & None \\
DeFi Llama & \texttt{stablecoins.llama.fi/stablecoins} & 300/5min & None \\
FRED & \texttt{api.stlouisfed.org/fred/series} & None & API Key \\
CoinGecko & \texttt{api.coingecko.com/api/v3} & 10-50/min & API Key (Pro) \\
Token Terminal & \texttt{api.tokenterminal.com/v2} & Varies & API Key \\
\bottomrule
\end{tabularx}
\end{table*}

% ============================================================================
% APPENDIX C: SUB-INDEX CALCULATION CODE
% ============================================================================

\section{Sub-Index Calculation Code}

Python implementation of sub-index formulas is available in the repository at \texttt{src/asri/signals/calculator.py}. Key functions:

\begin{verbatim}
def calculate_stablecoin_risk(
    tvl_ratio: float,
    treasury_weight: float,
    hhi_concentration: float,
    peg_volatility: float
) -> float:
    return (
        0.4 * tvl_ratio +
        0.3 * treasury_weight +
        0.2 * hhi_concentration +
        0.1 * peg_volatility
    )
\end{verbatim}

Full implementation: \href{https://github.com/studiofarzulla/asri}{\texttt{github.com/studiofarzulla/asri}}

% ============================================================================
% APPENDIX D: EVENT STUDY PROTOCOL SPECIFICATION
% ============================================================================

\section{Event Study Protocol Specification}\label{app:event_study_protocol}

This appendix provides the complete methodological specification for the event study analysis, addressing reviewer concerns regarding pre-registration, window selection, multiple testing correction, and placebo testing.

\subsection{Pre-Registration and Event Selection}

\subsubsection{Event Identification Criteria}

Crisis events were identified \textit{ex ante} based on three jointly necessary conditions:
\begin{enumerate}
    \item \textbf{Magnitude}: Market capitalization decline $\geq 15\%$ within 7 days, or single-asset collapse $\geq 50\%$ for assets with market cap $\geq \$10$B
    \item \textbf{Contagion}: Cross-asset correlation surge $\bar{\rho}_t - \bar{\rho}_{t-30} \geq 0.20$
    \item \textbf{Duration}: Elevated stress persisting $\geq 5$ trading days
\end{enumerate}

Event dates were sourced from external references (CoinDesk, Bloomberg, Reuters) prior to ASRI analysis, preventing data snooping on threshold selection.

\subsubsection{Pre-Specified Parameters}

The following parameters were fixed before analysis:
\begin{itemize}
    \item Estimation window: $T_{\text{est}} = 60$ days ($t = -90$ to $t = -31$ relative to event)
    \item Event window: $T_{\text{event}} = 41$ days ($t = -30$ to $t = +10$)
    \item Significance level: $\alpha = 0.05$ (two-tailed)
    \item Lead time detection: 1.5 standard deviations above estimation-window mean
\end{itemize}

\subsection{Window Selection Justification}

\subsubsection{Estimation Window: $[-90, -31]$}

The 60-day estimation window was selected based on:
\begin{enumerate}
    \item \textbf{Statistical power}: $n = 60$ provides adequate precision for mean and variance estimation while avoiding excessive smoothing of regime-dependent dynamics
    \item \textbf{Regime stability}: ASRI exhibits regime persistence $> 94\%$, making 60 days sufficient to capture baseline behavior within a regime
    \item \textbf{Contamination avoidance}: The 30-day buffer ($t = -31$ cutoff) ensures estimation is complete before pre-crisis stress begins
\end{enumerate}

\textbf{Robustness}: Alternative estimation windows (45 days, 90 days) produce qualitatively identical results (all events significant at $p < 0.01$).

\subsubsection{Event Window: $[-30, +10]$}

The asymmetric event window reflects ASRI's design as an \textit{early warning} system:
\begin{itemize}
    \item \textbf{Pre-event ($-30$ to $-1$)}: Captures lead time---the period where ASRI begins detecting stress buildup
    \item \textbf{Event day ($t = 0$)}: Crisis onset (price cascade initiation)
    \item \textbf{Post-event ($+1$ to $+10$)}: Captures immediate aftermath and stress persistence
\end{itemize}

The 30-day pre-event window is calibrated to expected ASRI lead times (29--30 days across events).

\subsection{Normal Model Specification}

The constant mean model was selected for expected ASRI:
\begin{equation}
\mathbb{E}[\text{ASRI}_t] = \hat{\mu} = \frac{1}{T_{\text{est}}} \sum_{\tau = -90}^{-31} \text{ASRI}_\tau
\end{equation}

\subsubsection{Model Selection Rationale}

\begin{enumerate}
    \item \textbf{Simplicity}: The constant mean model makes minimal parametric assumptions
    \item \textbf{Stationarity}: ASRI rejects unit root (ADF $p < 0.01$), validating level-based analysis
    \item \textbf{AR(1) Alternative}: Robustness testing with AR(1) dynamics produces equivalent significance conclusions (all $p < 0.01$) with slightly smaller CAS magnitudes
\end{enumerate}

\subsubsection{Variance Estimation}

\begin{equation}
\hat{\sigma}^2_{\text{AS}} = \frac{1}{T_{\text{est}} - 1} \sum_{\tau = -90}^{-31} (\text{ASRI}_\tau - \hat{\mu})^2
\end{equation}

Autocorrelation diagnostics (Ljung-Box test) indicate insignificant residual correlation beyond lag 15--20, supporting the standard error calculation:
\begin{equation}
\text{SE}(\text{CAS}) = \hat{\sigma}_{\text{AS}} \times \sqrt{T_{\text{event}}}
\end{equation}

\subsection{Multiple Testing Correction}

With $K = 4$ simultaneous hypothesis tests (one per crisis event), we apply Bonferroni correction:
\begin{equation}
\alpha_{\text{adj}} = \frac{\alpha}{K} = \frac{0.05}{4} = 0.0125
\end{equation}

\textbf{Results}: All four events remain significant at the corrected threshold:
\begin{itemize}
    \item Terra/Luna: $p < 0.001$ ($< 0.0125$ \checkmark)
    \item Celsius/3AC: $p < 0.001$ ($< 0.0125$ \checkmark)
    \item FTX Collapse: $p < 0.001$ ($< 0.0125$ \checkmark)
    \item SVB Crisis: $p < 0.001$ ($< 0.0125$ \checkmark)
\end{itemize}

The Bonferroni correction is conservative; alternative corrections (Holm-Bonferroni, Benjamini-Hochberg) would yield identical conclusions given the extreme significance levels.

\subsection{Window Independence}

Table~\ref{tab:window_independence} documents the temporal separation between crisis events.

\begin{table}[H]
\centering
\caption{Event Window Independence Verification}
\label{tab:window_independence}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
Event & Est. Start & Est. End & Evt. Start & Evt. End \\
\midrule
Terra/Luna & 2022-02-11 & 2022-04-11 & 2022-04-12 & 2022-05-22 \\
Celsius/3AC & 2022-03-19 & 2022-05-17 & 2022-05-18 & 2022-06-27 \\
FTX Collapse & 2022-08-13 & 2022-10-11 & 2022-10-12 & 2022-11-21 \\
SVB Crisis & 2022-12-11 & 2023-02-08 & 2023-02-09 & 2023-03-21 \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item Estimation windows (60 days) and event windows (41 days) are non-overlapping.
\item Terra/Celsius event windows overlap by $\approx 10$ days; estimation windows are independent.
\item FTX and SVB events are separated by $> 90$ days (fully independent).
\end{tablenotes}
\end{table}

The partial overlap between Terra/Luna and Celsius/3AC event windows does not invalidate the analysis, as:
\begin{enumerate}
    \item Estimation windows remain independent
    \item The events represent distinct crisis mechanisms (algorithmic stablecoin vs. CeFi lending)
    \item Separate CAS calculations use event-specific baselines
\end{enumerate}

\subsection{Placebo Testing}

To assess false positive rates under the null hypothesis of no crisis, we conduct placebo analysis on 10 randomly selected non-crisis dates.

\subsubsection{Placebo Date Selection}

Dates were drawn uniformly from the sample period (2021-01 to 2024-12) excluding:
\begin{itemize}
    \item 90-day windows around known crisis events
    \item First/last 90 days of sample (edge effects)
\end{itemize}

\subsubsection{Placebo Results}

\begin{table}[H]
\centering
\caption{Placebo Test Results}
\label{tab:placebo}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
Metric & Expected & Observed & Interpretation \\
\midrule
Significant at $\alpha = 0.05$ & 0.5 (10\%) & 1 (10\%) & Nominal \\
Significant at $\alpha = 0.01$ & 0.1 (1\%) & 0 (0\%) & Conservative \\
Mean $|t|$ (placebo) & --- & 1.24 & vs. 23.7 (crisis) \\
Max $|t|$ (placebo) & --- & 2.18 & vs. 32.6 (crisis) \\
\bottomrule
\end{tabular}
\end{table}

The placebo analysis confirms:
\begin{enumerate}
    \item False positive rate is consistent with nominal $\alpha$ levels
    \item Crisis events produce dramatically larger $t$-statistics than placebo dates
    \item The 19$\times$ difference in mean $|t|$ between crisis and placebo dates demonstrates genuine discriminative ability
\end{enumerate}

\subsection{Lead Time Measurement}

Two complementary lead time definitions are employed:

\textbf{Definition 1 (First-crossing)}: Days between first observation exceeding 1.5$\sigma$ above baseline and crisis onset. Captures earliest structural warning signal.

\textbf{Definition 2 (Final-sustained)}: Days between last observation below threshold before sustained elevation and crisis onset. Captures actionable intervention timing.

First-crossing lead times and final-sustained lead times may differ. The discrepancy between definitions (e.g., Terra/Luna: 72 days first-crossing vs. 30 days final-sustained) reflects ASRI fluctuations between initial detection and crisis onset.

\subsection{Sensitivity to Specification Choices}

\begin{table}[H]
\centering
\caption{Event Study Robustness to Specification Changes}
\label{tab:es_robustness}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
Specification & Terra & Celsius & FTX & SVB \\
\midrule
Baseline (60d, const. mean) & *** & *** & *** & *** \\
45-day estimation window & *** & *** & *** & *** \\
90-day estimation window & *** & *** & *** & *** \\
AR(1) normal model & *** & *** & *** & ** \\
Event window $[-20, +10]$ & *** & *** & *** & *** \\
Event window $[-40, +10]$ & *** & *** & *** & *** \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\small
\item *** $p < 0.01$, ** $p < 0.05$, * $p < 0.10$
\item All specifications detect all four crises at $p < 0.05$.
\end{tablenotes}
\end{table}

% ============================================================================
% BIBLIOGRAPHY
% ============================================================================

\bibliography{references}

\end{document}
