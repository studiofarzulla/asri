# ASRI Development Setup Guide

## âœ… Already Done
- Repository cloned to: `/home/andrewroyce/asri`
- Python virtual environment created at: `.venv`
- All dependencies installed (FastAPI, PostgreSQL drivers, Pandas, etc.)
- `.env` file created from template

---

## ğŸš€ Quick Start

```bash
cd /home/andrewroyce/asri
source .venv/bin/activate
```

---

## ğŸ“‹ What You Need Next

### 1. **PostgreSQL Database Setup**

#### Option A: Local PostgreSQL
```bash
# Install PostgreSQL
sudo apt update
sudo apt install postgresql postgresql-contrib

# Start PostgreSQL service
sudo systemctl start postgresql

# Create database and user
sudo -u postgres psql
CREATE DATABASE asri;
CREATE USER asri_user WITH ENCRYPTED PASSWORD 'your_secure_password';
GRANT ALL PRIVILEGES ON DATABASE asri TO asri_user;
\q
```

#### Option B: Docker PostgreSQL (Recommended)
```bash
# Create docker-compose.yml in project root
docker-compose up -d

# Or run directly:
docker run -d \
  --name asri-postgres \
  -e POSTGRES_DB=asri \
  -e POSTGRES_USER=asri_user \
  -e POSTGRES_PASSWORD=secure_password \
  -p 5432:5432 \
  postgres:15
```

Update `.env` with your database connection:
```
DATABASE_URL=postgresql+asyncpg://asri_user:secure_password@localhost:5432/asri
DATABASE_SYNC_URL=postgresql://asri_user:secure_password@localhost:5432/asri
```

### 2. **API Keys Required**

Edit `.env` and add your API keys:

#### Free (Recommended to start):
- **FRED API Key** (Free): https://fred.stlouisfed.org/docs/api/api_key.html
  - For macro economic indicators
  
#### Paid/Premium (Optional):
- **Token Terminal**: https://tokenterminal.com/
  - Protocol metrics and revenue data
  
- **Messari API**: https://messari.io/api
  - On-chain data and crypto metrics
  
- **DeFi Llama**: https://defillama.com/docs/api
  - No key needed, but rate limited

---

## ğŸ—ï¸ Components to Build

### Priority 1: Database Layer

#### Create Database Models (`src/asri/models/`)
```
src/asri/models/
â”œâ”€â”€ __init__.py (already exists)
â”œâ”€â”€ base.py          # SQLAlchemy Base setup
â”œâ”€â”€ asri.py          # ASRI daily values table
â”œâ”€â”€ sub_indices.py   # Sub-index values table
â””â”€â”€ raw_data.py      # Raw data from sources
```

**Files to create:**
1. `base.py` - Database connection and base model
2. `asri.py` - Store daily ASRI calculations
3. `sub_indices.py` - Store sub-index components
4. `raw_data.py` - Store raw ingested data

#### Create Database Migrations
```bash
# Install alembic for migrations
pip install alembic

# Initialize alembic
alembic init alembic

# Create first migration
alembic revision --autogenerate -m "Initial tables"
alembic upgrade head
```

### Priority 2: Data Ingestion Layer

#### Expand Connectors (`src/asri/ingestion/`)
```
src/asri/ingestion/
â”œâ”€â”€ __init__.py (already exists)
â”œâ”€â”€ defillama.py (already exists)
â”œâ”€â”€ token_terminal.py   # NEW - Token Terminal API
â”œâ”€â”€ fred.py             # NEW - FRED macro data
â”œâ”€â”€ messari.py          # NEW - Messari on-chain data
â””â”€â”€ base.py             # NEW - Base connector class
```

**Files to create:**
1. `base.py` - Abstract base class for all connectors
2. `token_terminal.py` - Protocol metrics
3. `fred.py` - Economic indicators
4. `messari.py` - On-chain data

### Priority 3: Data Processing Pipeline

#### Create ETL Pipeline (`src/asri/pipeline/`)
```
src/asri/pipeline/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ transform.py      # Raw data â†’ sub-index inputs
â”œâ”€â”€ calculate.py      # Compute sub-indices & ASRI
â””â”€â”€ store.py          # Save to database
```

### Priority 4: Scheduler for Daily Updates

#### Create Scheduler (`src/asri/scheduler/`)
```
src/asri/scheduler/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ jobs.py           # Define scheduled jobs
â””â”€â”€ runner.py         # APScheduler configuration
```

**Daily job flow:**
1. Fetch data from all sources (6 AM UTC)
2. Transform raw data
3. Calculate sub-indices
4. Calculate ASRI
5. Store in database

### Priority 5: Connect API to Database

**Update** `src/asri/api/main.py`:
- Replace placeholder responses with database queries
- Add database session dependency
- Implement actual data retrieval

---

## ğŸ“ Recommended File Structure

```
asri/
â”œâ”€â”€ src/asri/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py (âœ… exists, needs DB connection)
â”‚   â”‚   â”œâ”€â”€ dependencies.py (NEW - DB session, auth)
â”‚   â”‚   â””â”€â”€ schemas.py (NEW - Pydantic response models)
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ base.py (NEW)
â”‚   â”‚   â”œâ”€â”€ defillama.py (âœ… exists)
â”‚   â”‚   â”œâ”€â”€ token_terminal.py (NEW)
â”‚   â”‚   â”œâ”€â”€ fred.py (NEW)
â”‚   â”‚   â””â”€â”€ messari.py (NEW)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py (NEW)
â”‚   â”‚   â”œâ”€â”€ asri.py (NEW)
â”‚   â”‚   â”œâ”€â”€ sub_indices.py (NEW)
â”‚   â”‚   â””â”€â”€ raw_data.py (NEW)
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py (NEW)
â”‚   â”‚   â”œâ”€â”€ transform.py (NEW)
â”‚   â”‚   â”œâ”€â”€ calculate.py (NEW)
â”‚   â”‚   â””â”€â”€ store.py (NEW)
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â”œâ”€â”€ __init__.py (NEW)
â”‚   â”‚   â”œâ”€â”€ jobs.py (NEW)
â”‚   â”‚   â””â”€â”€ runner.py (NEW)
â”‚   â”œâ”€â”€ signals/
â”‚   â”‚   â””â”€â”€ calculator.py (âœ… exists)
â”‚   â””â”€â”€ config.py (NEW - Load .env settings)
â”œâ”€â”€ alembic/ (NEW - DB migrations)
â”œâ”€â”€ scripts/ (NEW - utility scripts)
â”‚   â”œâ”€â”€ init_db.py
â”‚   â”œâ”€â”€ backfill_data.py
â”‚   â””â”€â”€ test_sources.py
â””â”€â”€ tests/
    â”œâ”€â”€ test_calculator.py (âœ… exists)
    â”œâ”€â”€ test_ingestion.py (NEW)
    â”œâ”€â”€ test_models.py (NEW)
    â””â”€â”€ test_pipeline.py (NEW)
```

---

## ğŸ§ª Testing Your Setup

```bash
# Activate environment
cd /home/andrewroyce/asri
source .venv/bin/activate

# Run existing tests
pytest

# Start development server (will use placeholder data)
uvicorn asri.api.main:app --reload

# Visit in browser:
# http://localhost:8000/docs (Swagger UI)
# http://localhost:8000/health
# http://localhost:8000/asri/current
```

---

## ğŸ“ Development Workflow

### Phase 1: Foundation (Week 1)
1. Set up PostgreSQL database
2. Create database models
3. Create and run migrations
4. Test database connectivity

### Phase 2: Data Ingestion (Week 2-3)
1. Get FRED API key (free)
2. Build additional data connectors
3. Test each connector independently
4. Create data validation logic

### Phase 3: Processing Pipeline (Week 3-4)
1. Build ETL pipeline
2. Transform raw data to sub-index inputs
3. Connect calculator to database
4. Validate calculations

### Phase 4: Scheduler & Automation (Week 4)
1. Set up APScheduler
2. Create daily update job
3. Add error handling and logging
4. Test full pipeline end-to-end

### Phase 5: API Integration (Week 5)
1. Connect API endpoints to database
2. Add query parameters and filters
3. Implement rate limiting
4. Add API authentication

### Phase 6: Polish (Week 6)
1. Add comprehensive tests
2. Write documentation
3. Set up CI/CD
4. Deploy to production

---

## ğŸ”§ Useful Commands

```bash
# Activate environment
source .venv/bin/activate

# Run linter
ruff check src/

# Format code
ruff format src/

# Type checking
mypy src/

# Run tests with coverage
pytest --cov=src/asri --cov-report=html

# Start API server
uvicorn asri.api.main:app --reload --port 8000

# Run database migrations
alembic upgrade head

# Create new migration
alembic revision --autogenerate -m "description"
```

---

## ğŸ“š Key Documentation Links

- **FastAPI**: https://fastapi.tiangolo.com/
- **SQLAlchemy**: https://docs.sqlalchemy.org/
- **Pydantic**: https://docs.pydantic.dev/
- **APScheduler**: https://apscheduler.readthedocs.io/
- **Alembic**: https://alembic.sqlalchemy.org/
- **DeFi Llama API**: https://defillama.com/docs/api
- **FRED API**: https://fred.stlouisfed.org/docs/api/

---

## ğŸ†˜ Troubleshooting

### Database Connection Issues
```bash
# Check if PostgreSQL is running
sudo systemctl status postgresql

# Test connection
psql -h localhost -U asri_user -d asri
```

### Import Errors
```bash
# Reinstall in editable mode
pip install -e ".[dev]"
```

### Port Already in Use
```bash
# Find process using port 8000
lsof -i :8000

# Use different port
uvicorn asri.api.main:app --reload --port 8001
```

---

## ğŸ¯ Next Immediate Steps

1. **Set up PostgreSQL** (see section 1 above)
2. **Get FRED API key** (free, takes 2 minutes)
3. **Create database models** (start with `src/asri/models/base.py`)
4. **Test API** (`uvicorn asri.api.main:app --reload`)

The foundation is ready - you can start building! ğŸš€
